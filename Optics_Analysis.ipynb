{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "348e0a7c-f02b-435e-9139-795f5c9f540a",
   "metadata": {
    "id": "348e0a7c-f02b-435e-9139-795f5c9f540a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "import os\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f003f7-fe04-4439-a508-79907c7034fd",
   "metadata": {
    "id": "32f003f7-fe04-4439-a508-79907c7034fd"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa137afb-4ee7-4738-b76f-5bdaeee73ba7",
   "metadata": {
    "id": "aa137afb-4ee7-4738-b76f-5bdaeee73ba7"
   },
   "source": [
    "An npz data file contains: ['time1', 'time2', 'timeoffset', 'timescale', 'voltscale', 'voltoffset', 'raw_data_chan1', 'raw_data_chan2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7647e4bf-ac1c-4d2f-93d0-626d976516da",
   "metadata": {
    "id": "7647e4bf-ac1c-4d2f-93d0-626d976516da"
   },
   "outputs": [],
   "source": [
    "def mean_maker(name, chan1 = False, chan2 = False): # only one channel at a time is callable atm because i think otherwise i have to also put that whole shebag in the frame and i dont want that\n",
    "    fn = folder + name\n",
    "    data = np.load(fn)\n",
    "#     lst = data.files\n",
    "    if chan1 :\n",
    "        return np.mean(data['raw_data_chan1'])\n",
    "    elif chan2:\n",
    "        return np.mean(data['raw_data_chan2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c155f43-47b7-4491-b286-04ae7ef55835",
   "metadata": {
    "id": "7c155f43-47b7-4491-b286-04ae7ef55835"
   },
   "outputs": [],
   "source": [
    "def std_dev(name, chan1 = False, chan2 = False): # only one channel at a time is callable atm because i think otherwise i have to also put that whole shebag in the frame and i dont want that\n",
    "    fn = folder + name\n",
    "    data = np.load(fn)\n",
    "#     lst = data.files\n",
    "    if chan1 :\n",
    "        return np.std(data['raw_data_chan1'])\n",
    "    elif chan2:\n",
    "        return np.std(data['raw_data_chan2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa403312-9af1-458f-8de2-7de3ea18d1a9",
   "metadata": {
    "id": "aa403312-9af1-458f-8de2-7de3ea18d1a9"
   },
   "outputs": [],
   "source": [
    "def find_change_points(data, threshold):\n",
    "    # Calculate the gradient of the data\n",
    "    gradient = np.gradient(data)\n",
    "\n",
    "    # Find positions where the absolute gradient exceeds the threshold\n",
    "    change_points = np.where(np.abs(gradient) > threshold)[0]\n",
    "\n",
    "    return change_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d180c52-c25d-4768-9ca5-85fdd5c07453",
   "metadata": {
    "id": "7d180c52-c25d-4768-9ca5-85fdd5c07453"
   },
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), \"valid\") / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "449de8b9-d226-4019-97c4-0d35bed0b861",
   "metadata": {
    "id": "449de8b9-d226-4019-97c4-0d35bed0b861"
   },
   "outputs": [],
   "source": [
    "def find_range(EF_data, photo_data, threshold=20):\n",
    "#     EF_data = moving_average(EF_data, 2)\n",
    "    points = find_change_points(EF_data, threshold)\n",
    "    cut_ratio = points/EF_data.size\n",
    "    photo_cut = photo_data[int(photo_data.size*min(cut_ratio)):int(photo_data.size*max(cut_ratio))]\n",
    "    background_cut = photo_data[0:int(photo_data.size*min(cut_ratio))]\n",
    "    return photo_cut, background_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd7093cb-8873-4fb5-b83b-f371ce512829",
   "metadata": {
    "id": "cd7093cb-8873-4fb5-b83b-f371ce512829"
   },
   "outputs": [],
   "source": [
    "def get_data(name, chan):\n",
    "    fn = folder + name\n",
    "    data = np.load(fn)\n",
    "    return data['raw_data_chan'+str(chan)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a40da1ae-f9e2-4eef-afd2-c5b342ef97e4",
   "metadata": {
    "id": "a40da1ae-f9e2-4eef-afd2-c5b342ef97e4"
   },
   "outputs": [],
   "source": [
    "def get_fulldata(name):\n",
    "    fn = folder + name\n",
    "    data = np.load(fn)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bc41ef3-016f-42da-948e-55725114aa20",
   "metadata": {
    "id": "6bc41ef3-016f-42da-948e-55725114aa20"
   },
   "outputs": [],
   "source": [
    "def new_array(data):\n",
    "    #for some reason the array loaded from the npz SUCKS, maybe someone can help and do it better\n",
    "    #here I just create a new numpy array that can be used better!!!\n",
    "    data_new = np.zeros(data.size)\n",
    "    for i in range(data.size):\n",
    "        data_new[i] = data[i]\n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d5318ad-b180-4717-a783-46780dc669df",
   "metadata": {
    "id": "1d5318ad-b180-4717-a783-46780dc669df"
   },
   "outputs": [],
   "source": [
    "def voltage_converter(data, voltoffset, voltscale):\n",
    "#     # first, we convert the data such that the middle (125 pts) is at 0V\n",
    "#     data = data - 125\n",
    "#     #then we subtract the voltage offset converted into points, one unit of voltscale = -25 points\n",
    "#     data = data - ((voltoffset/voltscale) * -25)\n",
    "#     #then we convert from points to voltage\n",
    "#     data = data / -25\n",
    "#     #then we adjust the scale\n",
    "#     data = data * voltscale\n",
    "\n",
    "    data_new = (((data - 125) - ((voltoffset/voltscale) * -25))/ -25) * voltscale\n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e635e13-cf19-44ff-bedf-894693666111",
   "metadata": {
    "id": "8e635e13-cf19-44ff-bedf-894693666111"
   },
   "outputs": [],
   "source": [
    "def convert_all(name):\n",
    "    data = get_fulldata(name)\n",
    "    chan1 = data['raw_data_chan1']\n",
    "    chan2 = data['raw_data_chan2']\n",
    "    #Data saved before 04/11 has inverted volt offset and volt scale\n",
    "    vs = data['voltscale']\n",
    "    voff = data['voltoffset']\n",
    "    time1 = data['time1']\n",
    "    time2 = data['time2']\n",
    "    toff = data['timeoffset']\n",
    "    tscale = data['timescale']\n",
    "\n",
    "    chan1 = new_array(chan1)\n",
    "    chan2 = new_array(chan2)\n",
    "    chan1 = voltage_converter(chan1, voff[0], vs[0])\n",
    "    chan2 = voltage_converter(chan2, voff[1], vs[1])\n",
    "\n",
    "    return chan1, chan2, time1, time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80a3bd4f-4701-428c-8fba-09f97fa5b80d",
   "metadata": {
    "id": "80a3bd4f-4701-428c-8fba-09f97fa5b80d"
   },
   "outputs": [],
   "source": [
    "#the input of data needs to be in voltage and spits out the power measured by the RF channel of the photodiode\n",
    "def power_converter(data):\n",
    "    R = 0.3 #A/W\n",
    "    G = 50 *10^3 #V/A\n",
    "    new_data = data/(R*G) #Returns power in Watt\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e2b94bb-9c96-4d8a-ae7e-cdfbaa9cb762",
   "metadata": {
    "id": "7e2b94bb-9c96-4d8a-ae7e-cdfbaa9cb762"
   },
   "outputs": [],
   "source": [
    "# We start with 510 Watt, so the question is, how much do we lose? I don't think this is very valueable as a way to look at it , but it is possible\n",
    "def find_effect(data):\n",
    "    #how much do we lose through the first filter?\n",
    "    theta = 170-90\n",
    "    od = 0.0148 * theta\n",
    "    i = 510 * (10**(-od))\n",
    "    #Now this gets split in two\n",
    "    i_ref = i_s = i/2\n",
    "    #our sample beam also looses through the dichoric mirrors\n",
    "    i_s = i_s *0.92*0.92\n",
    "    #what we actually measure is the difference between our reference and our sample\n",
    "    i_tot = i_ref - i_s\n",
    "    #Now lets see how much higher the difference is in our data!\n",
    "    new_data = data - i_tot\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wz3NTyFiV8LH",
   "metadata": {
    "id": "wz3NTyFiV8LH"
   },
   "source": [
    "# fit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4wys059TWDMj",
   "metadata": {
    "id": "4wys059TWDMj"
   },
   "outputs": [],
   "source": [
    "def fit_cos_squared(x_data, y_data):\n",
    "    # Initial guess for the parameters A, B, C\n",
    "    params_covariance = 50\n",
    "    for i in range(1,3):\n",
    "        initial_guess = [1, i, 0]\n",
    "        # Use curve_fit to find the best fit parameters\n",
    "        params_1, params_covariance_1 = scipy.optimize.curve_fit(cos_squared, x_data, y_data, p0=initial_guess)\n",
    "        print(np.sum(params_covariance_1))\n",
    "        print(i)\n",
    "        if (np.sum(params_covariance_1) < params_covariance):\n",
    "            params = params_1\n",
    "            params_covariance = np.sum(params_covariance_1)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hx46OFEUW0UF",
   "metadata": {
    "id": "hx46OFEUW0UF"
   },
   "outputs": [],
   "source": [
    "def cos_squared(x, A, B, C):\n",
    "    \"\"\"Cosine squared function.\"\"\"\n",
    "    return A * np.cos(B * np.radians((x + C)))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5c39113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_norm(data):\n",
    "    min = np.min(data)\n",
    "    if min < 0 :\n",
    "        data = data + np.abs(min)\n",
    "    max = np.max(data)\n",
    "    return data/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1acd2cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit(x_data, y_data, params):\n",
    "    \"\"\"Plots the original data and the fitted curve.\"\"\"\n",
    "    plt.scatter(x_data, y_data, label='Data')\n",
    "    plt.plot(x_data, cos_squared(x_data, *params), label='Fitted function', color='red')\n",
    "#     formula_text = f'$y = {params[0]:.2f}  \\cdot \\cos^2( {params[1]:.2f} \\cdot x + {params[2]:.2f})$'\n",
    "#     plt.text(0.05, 0.95, formula_text, transform=plt.gca().transAxes,\n",
    "#              fontsize=12, verticalalignment='top', bbox=dict(facecolor='white', alpha=0.8))\n",
    "    plt.legend()\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('ITO ')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
